{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0, 1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "no_randomness = False\n",
    "load_weights = False\n",
    "semi_random = False\n",
    "\n",
    "class replay_memory(object):\n",
    "    def __init__(self, size, sd, b):\n",
    "        self.max_size = size\n",
    "        self.storage = []\n",
    "        self.cur_size = 0\n",
    "        self.batch_size = b\n",
    "        self.index = 0 \n",
    "        \n",
    "    def add(self, s,a,r,ns,d):\n",
    "        if self.cur_size < self.max_size:\n",
    "            self.storage.append([{\"s\":s, \"a\":a, \"r\":r, \"ns\":ns, \"d\":d}])\n",
    "            self.cur_size += 1\n",
    "        else:\n",
    "            self.storage.pop(0)\n",
    "            self.storage.append([{\"s\":s, \"a\":a, \"r\":r, \"ns\":ns, \"d\":d}])\n",
    "            \n",
    "    def sample(self):\n",
    "        s = []\n",
    "        a = []\n",
    "        r = []\n",
    "        ns = []\n",
    "        d = []\n",
    "        for i in range(self.batch_size):\n",
    "            indx = torch.randint(self.cur_size, size=(1,)).numpy()[0]\n",
    "            if no_randomness:\n",
    "                indx = i\n",
    "            if semi_random:\n",
    "                indx = self.index\n",
    "                if self.index < self.cur_size-1 and self.index < self.max_size-1:\n",
    "                    self.index += 1\n",
    "                else:\n",
    "                    self.index = 0 \n",
    "            s += [self.storage[indx][0][\"s\"]]\n",
    "            a += [self.storage[indx][0][\"a\"]]\n",
    "            r += [self.storage[indx][0][\"r\"]]\n",
    "            ns += [self.storage[indx][0][\"ns\"]]\n",
    "            d += [self.storage[indx][0][\"d\"]]\n",
    "            \n",
    "        return {\"s\":s, \"a\":a, \"r\":r, \"ns\":ns, \"d\":d}\n",
    "    \n",
    "\n",
    "def get_action_(env, epsilon, action):\n",
    "    if no_randomness:\n",
    "        epsilon = 0 \n",
    "    if semi_random:\n",
    "        x=np.squeeze(action_ts.detach().numpy())\n",
    "        if np.sum(x) < 10:\n",
    "            if 2*np.log(x[0]) - 5 > 3*np.log(x[1]) - 7:\n",
    "                a = 1\n",
    "            else:\n",
    "                a = 0 \n",
    "        else:\n",
    "            a = action.argmax().detach().numpy()            \n",
    "    else:\n",
    "        rnd = torch.rand((1)).numpy()[0]\n",
    "        if rnd < epsilon:\n",
    "            a = torch.randint(env.action_space.n, size=(1,)).numpy()[0]\n",
    "        else:\n",
    "            a = action.argmax().detach().to(cpu_device).numpy()\n",
    "        \n",
    "    return a\n",
    "    \n",
    "class exploration(object):\n",
    "    def __init__(self, max_,min_,num_eps):\n",
    "        self.epsilon = max_\n",
    "        self.min_eps = min_\n",
    "        self.num_eps = num_eps\n",
    "        self.eps_red = (max_ - min_)/num_eps\n",
    "    \n",
    "    def reduce(self):\n",
    "        if (self.epsilon > self.min_eps):\n",
    "            self.epsilon -= self.eps_red \n",
    "        \n",
    "        \n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, ni, no):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(ni,10)\n",
    "        self.fc2 = nn.Linear(10,10)\n",
    "        self.fc3 = nn.Linear(10,no)\n",
    "        if no_randomness and not load_weights:\n",
    "            self.fc1.weight.data.fill_(0.2)\n",
    "            self.fc2.weight.data.fill_(0.2)\n",
    "            self.fc3.weight.data.fill_(0.2)\n",
    "            self.fc1.bias.data.fill_(0.0)\n",
    "            self.fc2.bias.data.fill_(0.0)\n",
    "            self.fc3.bias.data.fill_(0.0)\n",
    "        elif load_weights:\n",
    "            d=np.loadtxt(\"fc1.weight\", delimiter=\",\")\n",
    "            self.fc1.weight.data = torch.tensor(d, dtype=torch.float32)\n",
    "            d=np.loadtxt(\"fc2.weight\", delimiter=\",\")\n",
    "            self.fc2.weight.data = torch.tensor(d, dtype=torch.float32)\n",
    "            d=np.loadtxt(\"fc3.weight\", delimiter=\",\")\n",
    "            self.fc3.weight.data = torch.tensor(d, dtype=torch.float32)\n",
    "            d=np.loadtxt(\"fc1.bias\", delimiter=\",\")\n",
    "            self.fc1.bias.data = torch.tensor(d, dtype=torch.float32)\n",
    "            d=np.loadtxt(\"fc2.bias\", delimiter=\",\")\n",
    "            self.fc2.bias.data = torch.tensor(d, dtype=torch.float32)\n",
    "            d=np.loadtxt(\"fc3.bias\", delimiter=\",\")            \n",
    "            self.fc3.bias.data = torch.tensor(d, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(torch.tensor(x).float().unsqueeze(0)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def test(period, avg_q, policy_net, env):\n",
    "    cnt = 0\n",
    "    for i in range(100):\n",
    "        state = env.reset()    \n",
    "        done = False\n",
    "        while not done:\n",
    "            action = policy_net(torch.tensor(state).float().to(device))\n",
    "            action = get_action_(env, 0, action)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            cnt+=1\n",
    "            state = next_state\n",
    "    print (period, avg_q, cnt/100)\n",
    "    return cnt/100\n",
    "    \n",
    "def get_weight_norm(net):\n",
    "    grad_norm=0\n",
    "    for param in net.parameters():\n",
    "    #     print(param)\n",
    "        grad_norm += torch.norm(param)\n",
    "\n",
    "    return grad_norm\n",
    "\n",
    "def get_grad_norm(net):\n",
    "    grad_norm=0\n",
    "    for param in net.parameters():\n",
    "    #     print(param)\n",
    "        grad_norm += torch.norm(param.grad)\n",
    "\n",
    "    return grad_norm\n",
    "\n",
    "\n",
    "def get_grad_list(net):\n",
    "    grads=np.array([])\n",
    "    for param in net.parameters():\n",
    "        grads = np.concatenate((grads, param.grad.data.view(-1).detach().numpy()))\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-12 09:59:04,673] Making new env: CartPole-v0\n",
      "/usr/lib/python3.6/site-packages/gym/envs/registration.py:17: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n",
      "/usr/lib64/python3.6/site-packages/torch/nn/parallel/data_parallel.py:25: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "# policy_net = DQN(env.observation_space.shape[0], env.action_space.n).to(device) \n",
    "model = DQN(env.observation_space.shape[0], env.action_space.n).to(device) \n",
    "policy_net = torch.nn.DataParallel(model,device_ids=[0,1],output_device=0).cuda()\n",
    "\n",
    "target_model = DQN(env.observation_space.shape[0], env.action_space.n).to(device) \n",
    "target_net = torch.nn.DataParallel(target_model,device_ids=[0,1],output_device=0).cuda()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters())\n",
    "# optimizer = optim.SGD(policy_net.parameters(),lr=0.001)\n",
    "# torch.nn.utils.clip_grad_norm(policy_net.parameters(),max_norm=10,norm_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gym.__file__\n",
    "# env.reset()\n",
    "# torch.stack(batch[\"s\"]).shape[1]\n",
    "# print (policy_net.fc1.weight.data)\n",
    "# print (policy_net.fc1.bias.data)\n",
    "# for param in policy_net.parameters():\n",
    "#     print (param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0ace3a1d9306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m             target_Q = target_net(torch.stack(batch[\"ns\"]).float().to(device\n\u001b[1;32m     60\u001b[0m                     )).squeeze().max(2)[0].detach()\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_Q\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"d\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             QValue = policy_net(torch.stack(batch[\"s\"]).float().to(\n\u001b[1;32m     63\u001b[0m                 device)).squeeze().gather(1, torch.stack(batch[\"a\"]).to(device).unsqueeze(1))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Training loop\n",
    "if semi_random:\n",
    "    qvtxt = open('Q_value.txt', 'wb')\n",
    "    tmtxt = open('target_max.txt', 'wb')\n",
    "    tvtxt = open('target_value.txt', 'wb')\n",
    "    stxt = open('state_value.txt', 'wb')\n",
    "    nstxt = open('nstate_value.txt', 'wb')\n",
    "    atxt = open('action_value.txt', 'wb')\n",
    "    aqtxt = open('action_q.txt', 'wb')\n",
    "    bstxt = open('batch_state.txt', 'wb')\n",
    "    gntxt = open('grad_norm.txt', 'wb')\n",
    "    wntxt = open('weight_norm.txt', 'wb')\n",
    "    gtxt = open('grads.txt', 'wb')\n",
    "    ltxt = open('loss.txt', 'wb')\n",
    "batch_size = 128\n",
    "rbm = replay_memory(1000000,env.observation_space, batch_size)\n",
    "num_episodes = 2000\n",
    "exp = exploration(0.9, 0.05, num_episodes)\n",
    "stop_nm = 2080 # stops early at this train step \n",
    "show_details = 10060 # will print the details of last xx train_steps\n",
    "result = []\n",
    "show_detail = False\n",
    "target_update = 200 \n",
    "\n",
    "train_step = 0\n",
    "for i_episode in range(num_episodes):\n",
    "     # initialize state\n",
    "    state = env.reset()\n",
    "    # Select and perform an action    \n",
    "    # keep going until get to the goal state\n",
    "    cnt = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        cnt+=1\n",
    "        action_ts = policy_net(torch.tensor(state).float().unsqueeze(0).to(device)).squeeze()\n",
    "#         action_ts = policy_net(torch.tensor(state).float().to(device))\n",
    "        action = get_action_(env, exp.epsilon, action_ts)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        rbm.add(torch.tensor(state), torch.tensor(action), torch.tensor(reward), torch.tensor(next_state), \n",
    "               done)\n",
    "            \n",
    "        if (no_randomness or train_step > stop_nm - show_details):\n",
    "            if show_detail:\n",
    "                print (i_episode,\"-\",cnt,\"-\",rbm.cur_size, state, action_ts, action, reward, next_state, done)\n",
    "            if semi_random:\n",
    "                np.savetxt(stxt, np.expand_dims(state,0))\n",
    "                np.savetxt(nstxt, np.expand_dims(next_state,0))\n",
    "                np.savetxt(atxt, np.expand_dims(action,0))\n",
    "                np.savetxt(aqtxt, action_ts.detach().numpy())\n",
    "            \n",
    "        \n",
    "        if rbm.cur_size > 100:\n",
    "            if rbm.cur_size == 101:\n",
    "                print (\"started training\")\n",
    "            batch = rbm.sample()\n",
    "            \n",
    "            target_Q = target_net(torch.stack(batch[\"ns\"]).float().to(device\n",
    "                    )).squeeze().max(2)[0].detach()\n",
    "            target = 0.99 * target_Q*(1-torch.tensor(batch[\"d\"]).to(device).float()) + \\\n",
    "            torch.stack(batch[\"r\"]).to(device)\n",
    "            QValue = policy_net(torch.stack(batch[\"s\"]).float().to(\n",
    "                device)).squeeze().gather(1, torch.stack(batch[\"a\"]).to(device).unsqueeze(1))\n",
    "            \n",
    "            loss_model = F.mse_loss(QValue, target.unsqueeze(1))\n",
    "            loss = torch.nn.DataParallel(loss_model, device_ids=[0,1])\n",
    "\n",
    "            if (semi_random or no_randomness) and train_step > stop_nm - show_details:\n",
    "                if show_detail:\n",
    "                    print (i_episode, \"-\", train_step)\n",
    "                    print (np.array(batch[\"d\"],dtype=np.int))\n",
    "                    print ([i for i in torch.stack(batch[\"a\"]).numpy()])\n",
    "                tmp = [i for i in target_Q.numpy()]\n",
    "                if show_detail:\n",
    "                    print (tmp)\n",
    "                np.savetxt(tmtxt, np.expand_dims(np.array(tmp),0))\n",
    "                tmp = [i for i in target.numpy()]\n",
    "                if show_detail:\n",
    "                    print (tmp)\n",
    "                np.savetxt(tvtxt, np.expand_dims(np.array(tmp),0))\n",
    "                tmp = [i for i in np.squeeze(QValue.detach().numpy())]\n",
    "                if show_detail:\n",
    "                    print(tmp)\n",
    "                np.savetxt(qvtxt, np.expand_dims(np.array(tmp),0))\n",
    "                np.savetxt(bstxt, np.array(torch.stack(batch[\"s\"]).detach().numpy()))\n",
    "                            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_step+=1\n",
    "            \n",
    "            if (semi_random or no_randomness) and train_step > stop_nm - show_details:\n",
    "                grad_norm = get_grad_norm(policy_net)\n",
    "                np.savetxt(gntxt, np.expand_dims(np.array(grad_norm.detach().numpy()),0))    \n",
    "                grads = get_grad_list(policy_net)\n",
    "                np.savetxt(gtxt, np.expand_dims(grads,0))    \n",
    "                weight_norm = get_weight_norm(policy_net)\n",
    "                np.savetxt(wntxt, np.expand_dims(np.array(weight_norm.detach().numpy()),0))    \n",
    "                np.savetxt(ltxt, np.expand_dims(np.array(loss.detach().numpy()),0))    \n",
    " \n",
    "                \n",
    "#             for param in policy_net.parameters():\n",
    "#                 print(param.grad.data)\n",
    "                \n",
    "            if (no_randomness or semi_random) and train_step == stop_nm:\n",
    "                break\n",
    "                \n",
    "        state = next_state\n",
    "        if train_step > 1 and train_step%target_update==0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "#             print (\"\\n copied wights \\n\")\n",
    "\n",
    "            if no_randomness:\n",
    "                for param in policy_net.parameters():\n",
    "                    print(param)\n",
    "\n",
    "\n",
    "    if (no_randomness or semi_random) and train_step == stop_nm:\n",
    "        break\n",
    "            \n",
    "    if train_step>0 and i_episode%100 == 0:\n",
    "        try:\n",
    "#             print (\"qvalue\", QValue)\n",
    "#             print (\"target\", target)\n",
    "            per = test(i_episode, QValue.mean(), policy_net, env)\n",
    "        except:\n",
    "            per = test(i_episode, 0, policy_net, env)\n",
    "            \n",
    "        result += [ per]\n",
    "        #     print (cnt)\n",
    "    exp.reduce()\n",
    "        \n",
    "if semi_random:\n",
    "    env.close()\n",
    "    qvtxt.close()\n",
    "    tmtxt.close()\n",
    "    tvtxt.close()\n",
    "    stxt.close()\n",
    "    bstxt.close()\n",
    "    nstxt.close()\n",
    "    atxt.close()\n",
    "    aqtxt.close()\n",
    "    gntxt.close()\n",
    "    wntxt.close()\n",
    "    gtxt.close()\n",
    "    ltxt.close()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]], device='cuda:0',\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(batch[\"d\"]).reshape(2,64).to(device)\n",
    "torch.reshape(torch.tensor(batch[\"d\"]),())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net(torch.stack(batch[\"s\"]).float().to(device)).squeeze().shape\n",
    "# torch.stack(batch[\"s\"]).shape\n",
    "# .gather(1, torch.stack(batch[\"a\"]).to(device).unsqueeze(1))\n",
    "# torch.stack(batch[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
